---
title: "p8105_hw2_ml5363"
author: "Muxin Li"
date: "2025-09-23"
output: github_document
---

```{r}
library(tidyverse)
library(readxl)
library(haven)
```

## Problem 1
#### clean the data in pols-month.csv
```{r}
pols_month_df=
  read_csv("hw2data/pols-month.csv",na=c("NA",".",""))|>
  janitor::clean_names()|>
  separate(mon,into=c("year","month","day"), sep = "-")|>
  mutate(month=case_match(
    month,
    "01"~"Jan",
    "02"~"Feb",
    "03"~"Mar",
    "04"~"Apr",
    "05"~"May",
    "06"~"Jun",
    "07"~"Jul",
    "08"~"Aug",
    "09"~"Sep",
    "10"~"Oct",
    "11"~"Nov",
    "12"~"Dec"
  ))|>
  mutate(president=case_when(
    prez_dem==1~"dem",
    prez_gop==1~"gop"
  ))|>
  select(-prez_dem,-prez_gop,-day)|>
  mutate(year=as.integer(year))
  
```

#### clean the data in snp.csv
```{r}
snp_df=
  read_csv("hw2data/snp.csv",na=c("NA",".",""))|>
  janitor::clean_names()|>
  separate(date,into=c("month","day","year"), sep = "/")|>
  mutate(month=case_match(
    month,
    "01"~"Jan",
    "02"~"Feb",
    "03"~"Mar",
    "04"~"Apr",
    "05"~"May",
    "06"~"Jun",
    "07"~"Jul",
    "08"~"Aug",
    "09"~"Sep",
    "10"~"Oct",
    "11"~"Nov",
    "12"~"Dec"
  ))|>
  relocate(year,month)|>
  select(-day)|>
  mutate(
    year = as.integer(year),                
    year = if_else(year <= 20, 2000 + year, 1900 + year)
  )
```

#### clean the data in unemployment.csv
```{r}
unemployment_df=
  read_csv("hw2data/unemployment.csv",na=c("NA",".",""))|>
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment_rate"
  )|>
  janitor::clean_names()
```

#### join dataset
```{r}
pols_snp_df=
  left_join(pols_month_df,snp_df, by=c("year","month"))
pols_snp_unemployment_df=
  left_join(pols_snp_df,unemployment_df,by=c("year","month"))
write_csv(pols_snp_unemployment_df,"HW2_Problem_1.csv")
```

#### short answer for problem 1
After cleaning and merging these datasets, the resulting panel data frame has 11 variables, spanning the years 1947 to 2015. Key variables include year, month, counts of Democratic and Republican governors, senators, and representatives (gov_gop, gov_dem, sen_gop, sen_dem, rep_gop, rep_dem), the new president variable (with values "gop" or "dem"), the close variable for S&P index values, and unemployment_rate. This combined dataset enables a joint analysis of political leadership, stock market performance, unemployment, and macroeconomic cycles across around 70 years.

## Problem 2
```{r}
Mr_trash_df=
  read_excel("hw2data/202509 Trash Wheel Collection Data.xlsx",sheet = "Mr. Trash Wheel",skip=1,na=c("NA",".",""))|>
  janitor::clean_names()|>
  select(-x15,-x16)|>
  mutate(sports_balls=as.integer(sports_balls))|>
  mutate(name="Mr.trash")|>
  mutate(year = as.integer(year))

Professor_trash_df= 
  read_excel("hw2data/202509 Trash Wheel Collection Data.xlsx",sheet = "Professor Trash Wheel",skip=1,na=c("NA",".",""))|>
  janitor::clean_names()|>
  mutate(name="Professor")|>
  mutate(year = as.integer(year))

Gwynnda_trash_df= 
  read_excel("hw2data/202509 Trash Wheel Collection Data.xlsx",sheet = "Gwynns Falls Trash Wheel",skip=1, na=c("NA",".",""))|>
  janitor::clean_names()|>
  mutate(name="Gwynnda")|>
  mutate(year = as.integer(year))

trash_wheel=
  bind_rows(Mr_trash_df,Professor_trash_df,Gwynnda_trash_df)
trash_wheel

num_Professor_weight=  
  select(Professor_trash_df,"weight_tons")|>
  sum()
num_cigarette_Gwynnda=
  filter(Gwynnda_trash_df,month== "June", year== 2022)|>
  select("cigarette_butts")|>
  sum()

```
#### short answer for Problem 2
After combining data from the three Trash Wheels into a single tidy dataset, we obtained `r nrow(trash_wheel)` total observations, each with variables such as `dumpster`, `date`, `weight_tons`.
These data provide insight into the volume and type of debris collected over time by each Trash Wheel. 
Professor Trash Wheel has collected a total of `r num_Professor_weight` tons of trash, and Gwynnda alone collected `r num_cigarette_Gwynnda` cigarette butts during June 2022.

## Problem 3
#### tidy dataset
```{r}
zip_code_df=
  read_csv("zillow_data/Zip Codes.csv",na=c("NA",".",""))|>
  janitor::clean_names()|>
  select(-file_date,-state_fips)
zip_zori_df=
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv",na=c("NA",".",""))|>
  janitor::clean_names()|>
  rename(zip_code=region_name)|>
  mutate(county_name = str_remove(county_name, " County$"))|>
  select(-region_type,-state_name,-state,-city,-metro,-county_name)

zip_df=
  left_join(zip_code_df,zip_zori_df,by=c("zip_code"))|>
  relocate(zip_code)
missing_zip=anti_join(zip_code_df,zip_zori_df,c="zip_code")
zip_df
```
The resulting tidy dataset contains `r nrow(zip_df)` total observations,
covering `r n_distinct(zip_df$zip_code)` unique ZIP codes across `r n_distinct(zip_df$neighborhood)` neighborhoods.
`r n_distinct(missing_zip$zip_code)`appear in the ZIP code dataset but not in the Zillow Rental Price dataset, perhaps due to privacy concerns, the data is missing.

#### January 2021 vs January 2020
```{r}
zip_tidy=
  pivot_longer(
    zip_df,
    x2015_01_31:x2024_08_31,
    names_to = "time",
    values_to = "zori"
  )
zip_tidy2=drop_na(zip_tidy,zori)
zip_202101=filter(zip_tidy2,time==("x2021_01_31"))
zip_202001=filter(zip_tidy2,time==("x2020_01_31"))
zip_20212020=
  bind_rows(zip_202001,zip_202101)|>
  relocate(zip_code,county_code, time)|>
  pivot_wider(
    names_from = "time",
    values_from = "zori"
  )
zip_20212020
drop_10=
  mutate(zip_20212020,drop=x2020_01_31-x2021_01_31)|>
  arrange(desc(drop))|>
  slice(1:10)
drop_10
```
#### short answer for Problem 3
The largest declines were concentrated in Manhattan (New York County), especially in the core areas such as Lower Manhattan and the decline was particularly significant. 
Possible reasons:
The pandemic in 2020-2021 severely affected the rental demand in downtown New York. Many residents moved away from high-density communities and shifted to suburbs or areas with more convenient remote working options, resulting in a decline in Manhattan rents.
