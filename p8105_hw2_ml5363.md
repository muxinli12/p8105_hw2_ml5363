p8105_hw2_ml5363
================
Muxin Li
2025-09-23

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
library(haven)
```

## Problem 1

#### clean the data in pols-month.csv

``` r
pols_month_df=
  read_csv("hw2data/pols-month.csv",na=c("NA",".",""))|>
  janitor::clean_names()|>
  separate(mon,into=c("year","month","day"), sep = "-")|>
  mutate(month=case_match(
    month,
    "01"~"Jan",
    "02"~"Feb",
    "03"~"Mar",
    "04"~"Apr",
    "05"~"May",
    "06"~"Jun",
    "07"~"Jul",
    "08"~"Aug",
    "09"~"Sep",
    "10"~"Oct",
    "11"~"Nov",
    "12"~"Dec"
  ))|>
  mutate(president=case_when(
    prez_dem==1~"dem",
    prez_gop==1~"gop"
  ))|>
  select(-prez_dem,-prez_gop,-day)|>
  mutate(year=as.integer(year))
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### clean the data in snp.csv

``` r
snp_df=
  read_csv("hw2data/snp.csv",na=c("NA",".",""))|>
  janitor::clean_names()|>
  separate(date,into=c("month","day","year"), sep = "/")|>
  mutate(month=case_match(
    month,
    "01"~"Jan",
    "02"~"Feb",
    "03"~"Mar",
    "04"~"Apr",
    "05"~"May",
    "06"~"Jun",
    "07"~"Jul",
    "08"~"Aug",
    "09"~"Sep",
    "10"~"Oct",
    "11"~"Nov",
    "12"~"Dec"
  ))|>
  relocate(year,month)|>
  select(-day)|>
  mutate(
    year = as.integer(year),                
    year = if_else(year <= 20, 2000 + year, 1900 + year)
  )
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### clean the data in unemployment.csv

``` r
unemployment_df=
  read_csv("hw2data/unemployment.csv",na=c("NA",".",""))|>
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment_rate"
  )|>
  janitor::clean_names()
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### join dataset

``` r
pols_snp_df=
  left_join(pols_month_df,snp_df, by=c("year","month"))
pols_snp_unemployment_df=
  left_join(pols_snp_df,unemployment_df,by=c("year","month"))
write_csv(pols_snp_unemployment_df,"HW2_Problem_1.csv")
```

#### short answer for problem 1

After cleaning and merging these datasets, the resulting panel data
frame has 11 variables, spanning the years 1947 to 2015. Key variables
include year, month, counts of Democratic and Republican governors,
senators, and representatives (gov_gop, gov_dem, sen_gop, sen_dem,
rep_gop, rep_dem), the new president variable (with values “gop” or
“dem”), the close variable for S&P index values, and unemployment_rate.
This combined dataset enables a joint analysis of political leadership,
stock market performance, unemployment, and macroeconomic cycles across
around 70 years.

## Problem 2

``` r
Mr_trash_df=
  read_excel("hw2data/202509 Trash Wheel Collection Data.xlsx",sheet = "Mr. Trash Wheel",skip=1,na=c("NA",".",""))|>
  janitor::clean_names()|>
  select(-x15,-x16)|>
  mutate(sports_balls=as.integer(sports_balls))|>
  mutate(name="Mr.trash")|>
  mutate(year = as.integer(year))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
Professor_trash_df= 
  read_excel("hw2data/202509 Trash Wheel Collection Data.xlsx",sheet = "Professor Trash Wheel",skip=1,na=c("NA",".",""))|>
  janitor::clean_names()|>
  mutate(name="Professor")|>
  mutate(year = as.integer(year))

Gwynnda_trash_df= 
  read_excel("hw2data/202509 Trash Wheel Collection Data.xlsx",sheet = "Gwynns Falls Trash Wheel",skip=1, na=c("NA",".",""))|>
  janitor::clean_names()|>
  mutate(name="Gwynnda")|>
  mutate(year = as.integer(year))

trash_wheel=
  bind_rows(Mr_trash_df,Professor_trash_df,Gwynnda_trash_df)
trash_wheel
```

    ## # A tibble: 1,191 × 15
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <int> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 1,181 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>, name <chr>

``` r
num_Professor_weight=  
  select(Professor_trash_df,"weight_tons")|>
  sum()
num_cigarette_Gwynnda=
  filter(Gwynnda_trash_df,month== "June", year== 2022)|>
  select("cigarette_butts")|>
  sum()
```

#### short answer for Problem 2

After combining data from the three Trash Wheels into a single tidy
dataset, we obtained 1191 total observations, each with variables such
as `dumpster`, `date`, `weight_tons`. These data provide insight into
the volume and type of debris collected over time by each Trash Wheel.
Professor Trash Wheel has collected a total of 564.52 tons of trash, and
Gwynnda alone collected 1.812^{4} cigarette butts during June 2022.

## Problem 3

#### tidy dataset

``` r
zip_code_df=
  read_csv("zillow_data/Zip Codes.csv",na=c("NA",".",""))|>
  janitor::clean_names()|>
  select(-file_date,-state_fips)
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
zip_zori_df=
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv",na=c("NA",".",""))|>
  janitor::clean_names()|>
  rename(zip_code=region_name)|>
  mutate(county_name = str_remove(county_name, " County$"))|>
  select(-region_type,-state_name,-state,-city,-metro,-county_name)
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
zip_df=
  left_join(zip_code_df,zip_zori_df,by=c("zip_code"))|>
  relocate(zip_code)
missing_zip=anti_join(zip_code_df,zip_zori_df,c="zip_code")
```

    ## Joining with `by = join_by(zip_code)`

``` r
zip_df
```

    ## # A tibble: 322 × 123
    ##    zip_code county county_code county_fips neighborhood      region_id size_rank
    ##       <dbl> <chr>  <chr>             <dbl> <chr>                 <dbl>     <dbl>
    ##  1    10451 Bronx  005               36005 High Bridge and …     61791       838
    ##  2    10452 Bronx  005               36005 High Bridge and …     61792       112
    ##  3    10453 Bronx  005               36005 Central Bronx         61793        84
    ##  4    10454 Bronx  005               36005 Hunts Point and …     61794      2018
    ##  5    10455 Bronx  005               36005 Hunts Point and …     61795      1733
    ##  6    10456 Bronx  005               36005 High Bridge and …     61796        49
    ##  7    10457 Bronx  005               36005 Central Bronx         61797       107
    ##  8    10458 Bronx  005               36005 Bronx Park and F…     61798        63
    ##  9    10459 Bronx  005               36005 Hunts Point and …     61799       914
    ## 10    10460 Bronx  005               36005 Central Bronx         61800       462
    ## # ℹ 312 more rows
    ## # ℹ 116 more variables: x2015_01_31 <dbl>, x2015_02_28 <dbl>,
    ## #   x2015_03_31 <dbl>, x2015_04_30 <dbl>, x2015_05_31 <dbl>, x2015_06_30 <dbl>,
    ## #   x2015_07_31 <dbl>, x2015_08_31 <dbl>, x2015_09_30 <dbl>, x2015_10_31 <dbl>,
    ## #   x2015_11_30 <dbl>, x2015_12_31 <dbl>, x2016_01_31 <dbl>, x2016_02_29 <dbl>,
    ## #   x2016_03_31 <dbl>, x2016_04_30 <dbl>, x2016_05_31 <dbl>, x2016_06_30 <dbl>,
    ## #   x2016_07_31 <dbl>, x2016_08_31 <dbl>, x2016_09_30 <dbl>, …

The resulting tidy dataset contains 322 total observations, covering 320
unique ZIP codes across 43 neighborhoods. 171appear in the ZIP code
dataset but not in the Zillow Rental Price dataset, perhaps due to
privacy concerns, the data is missing.

#### January 2021 vs January 2020

``` r
zip_tidy=
  pivot_longer(
    zip_df,
    x2015_01_31:x2024_08_31,
    names_to = "time",
    values_to = "zori"
  )
zip_tidy2=drop_na(zip_tidy,zori)
zip_202101=filter(zip_tidy2,time==("x2021_01_31"))
zip_202001=filter(zip_tidy2,time==("x2020_01_31"))
zip_20212020=
  bind_rows(zip_202001,zip_202101)|>
  relocate(zip_code,county_code, time)|>
  pivot_wider(
    names_from = "time",
    values_from = "zori"
  )
zip_20212020
```

    ## # A tibble: 97 × 9
    ##    zip_code county_code county county_fips neighborhood      region_id size_rank
    ##       <dbl> <chr>       <chr>        <dbl> <chr>                 <dbl>     <dbl>
    ##  1    10457 005         Bronx        36005 Central Bronx         61797       107
    ##  2    10458 005         Bronx        36005 Bronx Park and F…     61798        63
    ##  3    10461 005         Bronx        36005 Southeast Bronx       61801       894
    ##  4    10462 005         Bronx        36005 Southeast Bronx       61802       128
    ##  5    10463 005         Bronx        36005 Kingsbridge and …     61803       183
    ##  6    10467 005         Bronx        36005 Bronx Park and F…     61807        17
    ##  7    11201 047         Kings        36047 Northwest Brookl…     62012       222
    ##  8    11205 047         Kings        36047 Northwest Brookl…     62016      1025
    ##  9    11206 047         Kings        36047 Bushwick and Wil…     62017        47
    ## 10    11207 047         Kings        36047 East New York an…     62018        20
    ## # ℹ 87 more rows
    ## # ℹ 2 more variables: x2020_01_31 <dbl>, x2021_01_31 <dbl>

``` r
drop_10=
  mutate(zip_20212020,drop=x2020_01_31-x2021_01_31)|>
  arrange(desc(drop))|>
  slice(1:10)
drop_10
```

    ## # A tibble: 10 × 10
    ##    zip_code county_code county   county_fips neighborhood    region_id size_rank
    ##       <dbl> <chr>       <chr>          <dbl> <chr>               <dbl>     <dbl>
    ##  1    10007 061         New York       36061 Lower Manhattan     61621     10357
    ##  2    10069 061         New York       36061 <NA>                61664     10691
    ##  3    10009 061         New York       36061 Lower East Side     61623       531
    ##  4    10016 061         New York       36061 Gramercy Park …     61630       872
    ##  5    10001 061         New York       36061 Chelsea and Cl…     61615      4444
    ##  6    10002 061         New York       36061 Lower East Side     61616       139
    ##  7    10004 061         New York       36061 Lower Manhattan     61618     30490
    ##  8    10038 061         New York       36061 Lower Manhattan     61652      5069
    ##  9    10012 061         New York       36061 Greenwich Vill…     61626      5253
    ## 10    10010 061         New York       36061 Gramercy Park …     61624      2896
    ## # ℹ 3 more variables: x2020_01_31 <dbl>, x2021_01_31 <dbl>, drop <dbl>

#### short answer for Problem 3

The largest declines were concentrated in Manhattan (New York County),
especially in the core areas such as Lower Manhattan and the decline was
particularly significant. Possible reasons: The pandemic in 2020-2021
severely affected the rental demand in downtown New York. Many residents
moved away from high-density communities and shifted to suburbs or areas
with more convenient remote working options, resulting in a decline in
Manhattan rents.
